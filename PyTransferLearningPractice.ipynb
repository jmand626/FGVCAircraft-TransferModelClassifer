{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmand626/PyTorchMLEngine-Transfer-Learning/blob/main/PyTransferLearningPractice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the first cell, where image_path is defined\n",
        "from pathlib import Path\n",
        "\n",
        "# Define the path to the data folder\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"fgvc_aircraft\""
      ],
      "metadata": {
        "id": "9Sk080gYlXua"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import zipfile\n",
        "import requests\n",
        "\n",
        "# 1Ô∏è‚É£ Mount Google Drive (if using for storage)\n",
        "use_gdrive = False  # Set to True if dataset is stored in Google Drive\n",
        "if use_gdrive:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "# 2Ô∏è‚É£ Clone your GitHub repo if it's not already present\n",
        "repo_url = \"https://github.com/jmand626/PyTorchMLEngine-Custom-Dataset-Project.git\"\n",
        "repo_name = \"PyTorchMLEngine-Custom-Dataset-Project\"\n",
        "\n",
        "if not os.path.exists(repo_name):\n",
        "    print(f\"Cloning {repo_url}...\")\n",
        "    !git clone {repo_url}\n",
        "else:\n",
        "    print(f\"Repository {repo_name} already exists.\")\n",
        "\n",
        "# 3Ô∏è‚É£ Change to repo directory ONLY ONCE\n",
        "os.chdir(repo_name) # This line sets the working directory\n",
        "\n",
        "# 4Ô∏è‚É£ Add project files to sys.path so imports work\n",
        "sys.path.append(os.getcwd())\n",
        "print(\"Project directory added to sys.path\")\n",
        "\n",
        "# 5Ô∏è‚É£ Ensure necessary dependencies are installed\n",
        "try:\n",
        "    import torchinfo\n",
        "except ImportError:\n",
        "    print(\"Installing torchinfo...\")\n",
        "    !pip install -q torchinfo\n",
        "\n",
        "# 6Ô∏è‚É£ Download FGVC Aircraft dataset if missing\n",
        "dataset_url = \"https://www.robots.ox.ac.uk/~vgg/data/fgvc-aircraft/archives/fgvc-aircraft-2013b.tar.gz\"\n",
        "dataset_tar = data_path / \"fgvc-aircraft-2013b.tar.gz\"\n",
        "dataset_folder = data_path / \"fgvc-aircraft-2013b\"\n",
        "\n",
        "if dataset_folder.exists():\n",
        "    print(\"Dataset already exists.\")\n",
        "else:\n",
        "    print(\"Downloading FGVC Aircraft dataset...\")\n",
        "    data_path.mkdir(parents=True, exist_ok=True)\n",
        "    response = requests.get(dataset_url, stream=True)\n",
        "    with open(dataset_tar, \"wb\") as f:\n",
        "        for chunk in response.iter_content(chunk_size=8192):\n",
        "            f.write(chunk)\n",
        "    print(\"Extracting dataset...\")\n",
        "    !tar -xzf {dataset_tar} -C {data_path}\n",
        "    os.remove(dataset_tar)\n",
        "    print(\"Dataset extraction complete.\")"
      ],
      "metadata": {
        "id": "GzSakdlhzbLN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3b72556-6079-4029-9bc3-225a9576f9a4"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning https://github.com/jmand626/PyTorchMLEngine-Custom-Dataset-Project.git...\n",
            "Cloning into 'PyTorchMLEngine-Custom-Dataset-Project'...\n",
            "remote: Enumerating objects: 24, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 24 (delta 6), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (24/24), 21.93 KiB | 21.93 MiB/s, done.\n",
            "Resolving deltas: 100% (6/6), done.\n",
            "Project directory added to sys.path\n",
            "Downloading FGVC Aircraft dataset...\n",
            "Extracting dataset...\n",
            "Dataset extraction complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "xPSxUj-_Teyf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3404bda-ef19-4a24-b211-dc2773fa5f46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] torch/torchvision versions not as required, installing nightly versions.\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "torch version: 2.6.0+cu124\n",
            "torchvision version: 0.21.0+cu124\n"
          ]
        }
      ],
      "source": [
        "# For this notebook to run with updated APIs, we need torch 1.12+ and torchvision 0.13+\n",
        "try:\n",
        "    import torch\n",
        "    import torchvision\n",
        "    assert int(torch.__version__.split(\".\")[1]) >= 12, \"torch version should be 1.12+\"\n",
        "    assert int(torchvision.__version__.split(\".\")[1]) >= 13, \"torchvision version should be 0.13+\"\n",
        "    print(f\"torch version: {torch.__version__}\")\n",
        "    print(f\"torchvision version: {torchvision.__version__}\")\n",
        "except:\n",
        "    print(f\"[INFO] torch/torchvision versions not as required, installing nightly versions.\")\n",
        "    !pip3 install -U torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "    import torch\n",
        "    import torchvision\n",
        "    print(f\"torch version: {torch.__version__}\")\n",
        "    print(f\"torchvision version: {torchvision.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd PyTorchMLEngine-Custom-Dataset-Project\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpCWZh7Phbna",
        "outputId": "deffdef2-19ee-4887-9b89-5be8078e0e19"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/PyTorchMLEngine-Custom-Dataset-Project/PyTorchMLEngine-Custom-Dataset-Project/PyTorchMLEngine-Custom-Dataset-Project/PyTorchMLEngine-Custom-Dataset-Project/PyTorchMLEngine-Custom-Dataset-Project/PyTorchMLEngine-Custom-Dataset-Project/PyTorchMLEngine-Custom-Dataset-Project\n",
            "computer_vision_test_main.py  firsttry_model.py  README.md\n",
            "create_custom_dataset.py      model_backbone.py  setup_dataholders.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jt9KA4KSiTYJ",
        "outputId": "ce218a38-506f-4e38-9123-50f0e0711ddf"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now hopefully we can continously use the previous setup code whenever we want to use this dataset again."
      ],
      "metadata": {
        "id": "cMp0N0R2pW_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ipython-input-38-e84a44c78b2d\n",
        "# Assume the dataset is extracted to 'data/fgvc-aircraft-2013b'\n",
        "# and images are in 'data/fgvc-aircraft-2013b/data/images'\n",
        "from pathlib import Path # Make sure to import Path\n",
        "import os # Import os to get current working directory\n",
        "\n",
        "#Corrected paths:\n",
        "# Construct paths relative to the current directory (set in setup cell)\n",
        "# Assuming dataset is in 'data/fgvc-aircraft-2013b' relative to the notebook's root\n",
        "# The dataset is actually in \"PyTorchMLEngine-Custom-Dataset-Project/data/fgvc-aircraft-2013b\"\n",
        "train_dir = Path(\"data/fgvc-aircraft-2013b/data/images\")\n",
        "test_dir = Path(\"data/fgvc-aircraft-2013b/data/images\")  # Assuming test images are in the same location.\n",
        "\n",
        "# Fix: Update paths to include the subfolder where the dataset was downloaded and extracted\n",
        "train_dir = Path(\"PyTorchMLEngine-Custom-Dataset-Project/data/fgvc-aircraft-2013b/data/images\")\n",
        "test_dir = Path(\"PyTorchMLEngine-Custom-Dataset-Project/data/fgvc-aircraft-2013b/data/images\")  # Assuming test images are in the same location\n",
        "\n",
        "\n",
        "# Print the resolved paths to verify they are correct\n",
        "print(\"Train directory:\", train_dir)\n",
        "print(\"Test directory:\", test_dir)"
      ],
      "metadata": {
        "id": "tKnebh8NpT7G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03ce9ad7-e80a-4906-8059-506966d36c60"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train directory: PyTorchMLEngine-Custom-Dataset-Project/data/fgvc-aircraft-2013b/data/images\n",
            "Test directory: PyTorchMLEngine-Custom-Dataset-Project/data/fgvc-aircraft-2013b/data/images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we continue on to creating our datasets and dataloaders. An important issue is that we have to ensure that the data that we feed into our pretrained model must be formatted in the same way as the data inputted when training the model (helps performance immeasurably). There is a certain way that all models from torchvision.models require, and we will do that."
      ],
      "metadata": {
        "id": "JWvJSUvVtJYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "import setup_dataholders\n",
        "importlib.reload(setup_dataholders)\n",
        "manual_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # 1. Reshape all images to 224x224 (though some models may require different sizes)\n",
        "    transforms.ToTensor(), # 2. Turn image values to between 0 & 1\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], # 3. A mean of [0.485, 0.456, 0.406] (across each colour channel)\n",
        "                         std=[0.229, 0.224, 0.225]) # 4. A standard deviation of [0.229, 0.224, 0.225] (across each colour channel),\n",
        "])"
      ],
      "metadata": {
        "id": "I2wsd6E2t64w"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and testing DataLoaders as well as get a list of class names\n",
        "train_dataloader, test_dataloader, class_names = setup_dataholders.create_dataloaders(train_directory=train_dir,\n",
        "                                                                               test_directory=test_dir,\n",
        "                                                                               data_transforms=manual_transforms, # resize, convert images to between 0 & 1 and normalize them\n",
        "                                                                               batch_size=32, # set mini-batch size to 32\n",
        "                                                                               workers=4) # Fixed: removed type hint from the workers argument\n",
        "\n",
        "train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "TC7PU_cxr7He",
        "outputId": "9035c18a-c0a7-4204-ae0c-b2b9d17effeb"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'PyTorchMLEngine-Custom-Dataset-Project/data/fgvc-aircraft-2013b/data/images'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-e84a44c78b2d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create training and testing DataLoaders as well as get a list of class names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m train_dataloader, test_dataloader, class_names = setup_dataholders.create_dataloaders(train_directory=train_dir,\n\u001b[0m\u001b[1;32m      3\u001b[0m                                                                                \u001b[0mtest_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                                                                \u001b[0mdata_transforms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanual_transforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# resize, convert images to between 0 & 1 and normalize them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                                                \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# set mini-batch size to 32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/PyTorchMLEngine-Custom-Dataset-Project/PyTorchMLEngine-Custom-Dataset-Project/PyTorchMLEngine-Custom-Dataset-Project/PyTorchMLEngine-Custom-Dataset-Project/PyTorchMLEngine-Custom-Dataset-Project/PyTorchMLEngine-Custom-Dataset-Project/PyTorchMLEngine-Custom-Dataset-Project/setup_dataholders.py\u001b[0m in \u001b[0;36mcreate_dataloaders\u001b[0;34m(train_directory, test_directory, data_transforms, batch_size, workers)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# Create the datasets using ImageFolder and apply the provided transforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mtrain_augmented\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_transforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0mtest_transformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_transforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mallow_empty\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     ):\n\u001b[0;32m--> 328\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[0m\n\u001b[1;32m    147\u001b[0m     ) -> None:\n\u001b[1;32m    148\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         samples = self.make_dataset(\n\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(self, directory)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mmapping\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDatasetFolder\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \"\"\"\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't find any class folder in {directory}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'PyTorchMLEngine-Custom-Dataset-Project/data/fgvc-aircraft-2013b/data/images'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ISSUES BELOW**"
      ],
      "metadata": {
        "id": "_mS2GUl60Z4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Problems with importing files, so I had to manually add files to syspath\n",
        "import sys\n",
        "import os\n",
        "import importlib\n",
        "\n",
        "# Add the current working directory to sys.path\n",
        "sys.path.append(os.getcwd())\n",
        "\n",
        "# List of Python files you want to import\n",
        "modules = [\n",
        "    \"computer_vision_test_main\",\n",
        "    \"create_custom_dataset\",\n",
        "    \"firsttry_model\",\n",
        "    \"model_backbone\",\n",
        "    \"setup_dataholders\"\n",
        "]\n",
        "\n",
        "# Import each module and reload to avoid caching issues\n",
        "for module in modules:\n",
        "    try:\n",
        "        imported_module = __import__(module)\n",
        "        importlib.reload(imported_module)  # Reload in case it was modified\n",
        "        print(f\"Successfully imported {module}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error importing {module}: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVfrccwkyfmV",
        "outputId": "6dbe55f1-d928-4701-c885-40077a106c73"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error importing computer_vision_test_main: No module named 'FGVC_Aircraft'\n",
            "Creating image split for: train...\n",
            "Error importing create_custom_dataset: [Errno 2] No such file or directory: '../data/fgvc-aircraft-2013b/data/images/fgvc-aircraft-2013b/data/images_variant_train.txt'\n",
            "Successfully imported firsttry_model\n",
            "Successfully imported model_backbone\n",
            "Successfully imported setup_dataholders\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "dataset_path = \"data/fgvc-aircraft-2013b\"\n",
        "if os.path.exists(dataset_path):\n",
        "    print(\"‚úÖ Dataset folder exists.\")\n",
        "    print(\"üóÇ Contents:\", os.listdir(dataset_path))\n",
        "else:\n",
        "    print(\"‚ùå Dataset folder is missing.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6cF1NIRz3DI",
        "outputId": "5c6853dc-6efa-41a3-a50a-ac020c822cda"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ùå Dataset folder is missing.\n"
          ]
        }
      ]
    }
  ]
}