{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9Sk080gYlXua"
      },
      "outputs": [],
      "source": [
        "# This is the first cell, where image_path is defined\n",
        "from pathlib import Path\n",
        "\n",
        "# Define the path to the data folder\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"fgvc_aircraft\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzSakdlhzbLN",
        "outputId": "f3b72556-6079-4029-9bc3-225a9576f9a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning https://github.com/jmand626/PyTorchMLEngine-Custom-Dataset-Project.git...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cloning into 'PyTorchMLEngine-Custom-Dataset-Project'...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project directory added to sys.path\n",
            "Downloading FGVC Aircraft dataset...\n",
            "Extracting dataset...\n",
            "Dataset extraction complete.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import zipfile\n",
        "import requests\n",
        "\n",
        "# 1️⃣ Mount Google Drive (if using for storage)\n",
        "use_gdrive = False  # Set to True if dataset is stored in Google Drive\n",
        "if use_gdrive:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "# 2️⃣ Clone your GitHub repo if it's not already present\n",
        "repo_url = \"https://github.com/jmand626/PyTorchMLEngine-Custom-Dataset-Project.git\"\n",
        "repo_name = \"PyTorchMLEngine-Custom-Dataset-Project\"\n",
        "\n",
        "if not os.path.exists(repo_name):\n",
        "    print(f\"Cloning {repo_url}...\")\n",
        "    !git clone {repo_url}\n",
        "else:\n",
        "    print(f\"Repository {repo_name} already exists.\")\n",
        "\n",
        "# 3️⃣ Change to repo directory ONLY ONCE\n",
        "os.chdir(repo_name) # This line sets the working directory\n",
        "\n",
        "# 4️⃣ Add project files to sys.path so imports work\n",
        "sys.path.append(os.getcwd())\n",
        "print(\"Project directory added to sys.path\")\n",
        "\n",
        "# 5️⃣ Ensure necessary dependencies are installed\n",
        "try:\n",
        "    import torchinfo\n",
        "except ImportError:\n",
        "    print(\"Installing torchinfo...\")\n",
        "    !pip install -q torchinfo\n",
        "\n",
        "# 6️⃣ Download FGVC Aircraft dataset if missing\n",
        "dataset_url = \"https://www.robots.ox.ac.uk/~vgg/data/fgvc-aircraft/archives/fgvc-aircraft-2013b.tar.gz\"\n",
        "dataset_tar = data_path / \"fgvc-aircraft-2013b.tar.gz\"\n",
        "dataset_folder = data_path / \"fgvc-aircraft-2013b\"\n",
        "\n",
        "if dataset_folder.exists():\n",
        "    print(\"Dataset already exists.\")\n",
        "else:\n",
        "    print(\"Downloading FGVC Aircraft dataset...\")\n",
        "    data_path.mkdir(parents=True, exist_ok=True)\n",
        "    response = requests.get(dataset_url, stream=True)\n",
        "    with open(dataset_tar, \"wb\") as f:\n",
        "        for chunk in response.iter_content(chunk_size=8192):\n",
        "            f.write(chunk)\n",
        "    print(\"Extracting dataset...\")\n",
        "    !tar -xzf {dataset_tar} -C {data_path}\n",
        "    os.remove(dataset_tar)\n",
        "    print(\"Dataset extraction complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPSxUj-_Teyf",
        "outputId": "a3404bda-ef19-4a24-b211-dc2773fa5f46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] torch/torchvision versions not as required, installing nightly versions.\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
            "Requirement already satisfied: torch in c:\\users\\joban\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.6.0)\n",
            "Requirement already satisfied: torchvision in c:\\users\\joban\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.21.0)\n",
            "Requirement already satisfied: torchaudio in c:\\users\\joban\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.6.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\joban\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\joban\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in c:\\users\\joban\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\joban\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in c:\\users\\joban\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.12.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\joban\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (75.8.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\joban\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\joban\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\joban\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (2.2.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\joban\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\joban\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
            "torch version: 2.5.1+cpu\n",
            "torchvision version: 0.20.1+cpu\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# For this notebook to run with updated APIs, we need torch 1.12+ and torchvision 0.13+\n",
        "try:\n",
        "    import torch\n",
        "    import torchvision\n",
        "    assert int(torch.__version__.split(\".\")[1]) >= 12, \"torch version should be 1.12+\"\n",
        "    assert int(torchvision.__version__.split(\".\")[1]) >= 13, \"torchvision version should be 0.13+\"\n",
        "    print(f\"torch version: {torch.__version__}\")\n",
        "    print(f\"torchvision version: {torchvision.__version__}\")\n",
        "except:\n",
        "    print(f\"[INFO] torch/torchvision versions not as required, installing nightly versions.\")\n",
        "    !pip3 install -U torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "    import torch\n",
        "    import torchvision\n",
        "    print(f\"torch version: {torch.__version__}\")\n",
        "    print(f\"torchvision version: {torchvision.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpCWZh7Phbna",
        "outputId": "deffdef2-19ee-4887-9b89-5be8078e0e19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[WinError 2] The system cannot find the file specified: 'PyTorchMLEngine-Custom-Dataset-Project'\n",
            "c:\\Users\\joban\\Downloads\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'ls' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "%cd PyTorchMLEngine-Custom-Dataset-Project\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jt9KA4KSiTYJ",
        "outputId": "ce218a38-506f-4e38-9123-50f0e0711ddf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMp0N0R2pW_g"
      },
      "source": [
        "Now hopefully we can continously use the previous setup code whenever we want to use this dataset again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKnebh8NpT7G",
        "outputId": "03ce9ad7-e80a-4906-8059-506966d36c60"
      },
      "outputs": [],
      "source": [
        "# CORRECTED PATHS\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "# Print current directory to verify where we are\n",
        "print(f\"Current working directory: {os.getcwd()}\")\n",
        "\n",
        "# Since we already changed directory with os.chdir(repo_name) in cell 9,\n",
        "# we need to use relative paths from there, NOT including \"PyTorchMLEngine-Custom-Dataset-Project\" again\n",
        "train_dir = Path(\"data/fgvc-aircraft-2013b/data/images\")\n",
        "test_dir = Path(\"data/fgvc-aircraft-2013b/data/images\")\n",
        "\n",
        "# Another option is to use the eleven_group_subset dataset that exists\n",
        "alternative_train_dir = Path(\"data/eleven_group_subset_90_percent/train\")\n",
        "alternative_test_dir = Path(\"data/eleven_group_subset_90_percent/test\")\n",
        "\n",
        "# Check if paths exist\n",
        "print(f\"Does fgvc path exist? {os.path.exists(train_dir)}\")\n",
        "print(f\"Does eleven_group path exist? {os.path.exists(alternative_train_dir)}\")\n",
        "\n",
        "# List what's actually in the data directory\n",
        "print(\"\\nContents of data directory:\")\n",
        "for item in os.listdir(\"data\"):\n",
        "    print(f\"  - {item}\")\n",
        "\n",
        "# Use the alternative paths that actually exist\n",
        "train_dir = alternative_train_dir\n",
        "test_dir = alternative_test_dir\n",
        "\n",
        "print(\"\\nFINAL PATHS TO USE:\")\n",
        "print(f\"Train directory: {train_dir}\")\n",
        "print(f\"Test directory: {test_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWvJSUvVtJYy"
      },
      "source": [
        "Now we continue on to creating our datasets and dataloaders. An important issue is that we have to ensure that the data that we feed into our pretrained model must be formatted in the same way as the data inputted when training the model (helps performance immeasurably). There is a certain way that all models from torchvision.models require, and we will do that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "I2wsd6E2t64w"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "import setup_dataholders\n",
        "import importlib\n",
        "importlib.reload(setup_dataholders)\n",
        "manual_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # 1. Reshape all images to 224x224 (though some models may require different sizes)\n",
        "    transforms.ToTensor(), # 2. Turn image values to between 0 & 1\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], # 3. A mean of [0.485, 0.456, 0.406] (across each colour channel)\n",
        "                         std=[0.229, 0.224, 0.225]) # 4. A standard deviation of [0.229, 0.224, 0.225] (across each colour channel),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "TC7PU_cxr7He",
        "outputId": "9035c18a-c0a7-4204-ae0c-b2b9d17effeb"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "Couldn't find any class folder in data\\fgvc-aircraft-2013b\\data\\images.",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Create training and testing DataLoaders as well as get a list of class names\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m train_dataloader, test_dataloader, class_names = \u001b[43msetup_dataholders\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_dataloaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m                                                                               \u001b[49m\u001b[43mtest_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                                                                               \u001b[49m\u001b[43mdata_transforms\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmanual_transforms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# resize, convert images to between 0 & 1 and normalize them\u001b[39;49;00m\n\u001b[32m      5\u001b[39m \u001b[43m                                                                               \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# set mini-batch size to 32\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m                                                                               \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Fixed: removed type hint from the workers argument\u001b[39;00m\n\u001b[32m      8\u001b[39m train_dataloader, test_dataloader, class_names\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joban\\Downloads\\PyTorchMLEngine-Custom-Dataset-Project\\PyTorchMLEngine-Custom-Dataset-Project\\setup_dataholders.py:60\u001b[39m, in \u001b[36mcreate_dataloaders\u001b[39m\u001b[34m(train_directory, test_directory, data_transforms, batch_size, workers)\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[33;03mCreates DataLoaders for training and testing datasets.\u001b[39;00m\n\u001b[32m     29\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     56\u001b[39m \u001b[33;03m    )\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# Create the datasets using ImageFolder and apply the provided transforms\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m train_augmented = \u001b[43mdatasets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mImageFolder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_transforms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m test_transformed = datasets.ImageFolder(test_directory, transform=data_transforms)\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# Retrieve class names from the training dataset\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joban\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\datasets\\folder.py:328\u001b[39m, in \u001b[36mImageFolder.__init__\u001b[39m\u001b[34m(self, root, transform, target_transform, loader, is_valid_file, allow_empty)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    320\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    321\u001b[39m     root: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[32m   (...)\u001b[39m\u001b[32m    326\u001b[39m     allow_empty: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    327\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mIMG_EXTENSIONS\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_transform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m        \u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_valid_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    337\u001b[39m     \u001b[38;5;28mself\u001b[39m.imgs = \u001b[38;5;28mself\u001b[39m.samples\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joban\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\datasets\\folder.py:149\u001b[39m, in \u001b[36mDatasetFolder.__init__\u001b[39m\u001b[34m(self, root, loader, extensions, transform, target_transform, is_valid_file, allow_empty)\u001b[39m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    139\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    140\u001b[39m     root: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[32m   (...)\u001b[39m\u001b[32m    146\u001b[39m     allow_empty: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    147\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    148\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(root, transform=transform, target_transform=target_transform)\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m     classes, class_to_idx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m     samples = \u001b[38;5;28mself\u001b[39m.make_dataset(\n\u001b[32m    151\u001b[39m         \u001b[38;5;28mself\u001b[39m.root,\n\u001b[32m    152\u001b[39m         class_to_idx=class_to_idx,\n\u001b[32m   (...)\u001b[39m\u001b[32m    155\u001b[39m         allow_empty=allow_empty,\n\u001b[32m    156\u001b[39m     )\n\u001b[32m    158\u001b[39m     \u001b[38;5;28mself\u001b[39m.loader = loader\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joban\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\datasets\\folder.py:234\u001b[39m, in \u001b[36mDatasetFolder.find_classes\u001b[39m\u001b[34m(self, directory)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfind_classes\u001b[39m(\u001b[38;5;28mself\u001b[39m, directory: Union[\u001b[38;5;28mstr\u001b[39m, Path]) -> Tuple[List[\u001b[38;5;28mstr\u001b[39m], Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]]:\n\u001b[32m    208\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[32m    209\u001b[39m \n\u001b[32m    210\u001b[39m \u001b[33;03m        directory/\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    232\u001b[39m \u001b[33;03m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[32m    233\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfind_classes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\joban\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\datasets\\folder.py:43\u001b[39m, in \u001b[36mfind_classes\u001b[39m\u001b[34m(directory)\u001b[39m\n\u001b[32m     41\u001b[39m classes = \u001b[38;5;28msorted\u001b[39m(entry.name \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m os.scandir(directory) \u001b[38;5;28;01mif\u001b[39;00m entry.is_dir())\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCouldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt find any class folder in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdirectory\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     45\u001b[39m class_to_idx = {cls_name: i \u001b[38;5;28;01mfor\u001b[39;00m i, cls_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(classes)}\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m classes, class_to_idx\n",
            "\u001b[31mFileNotFoundError\u001b[39m: Couldn't find any class folder in data\\fgvc-aircraft-2013b\\data\\images."
          ]
        }
      ],
      "source": [
        "# Create training and testing DataLoaders as well as get a list of class names\n",
        "train_dataloader, test_dataloader, class_names = setup_dataholders.create_dataloaders(train_directory=train_dir,\n",
        "                                                                               test_directory=test_dir,\n",
        "                                                                               data_transforms=manual_transforms, # resize, convert images to between 0 & 1 and normalize them\n",
        "                                                                               batch_size=32, # set mini-batch size to 32\n",
        "                                                                               workers=4) # Fixed: removed type hint from the workers argument\n",
        "\n",
        "train_dataloader, test_dataloader, class_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mS2GUl60Z4g"
      },
      "source": [
        "**ISSUES BELOW**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVfrccwkyfmV",
        "outputId": "6dbe55f1-d928-4701-c885-40077a106c73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error importing computer_vision_test_main: No module named 'FGVC_Aircraft'\n",
            "Creating image split for: train...\n",
            "Error importing create_custom_dataset: [Errno 2] No such file or directory: '../data/fgvc-aircraft-2013b/data/images/fgvc-aircraft-2013b/data/images_variant_train.txt'\n",
            "Successfully imported firsttry_model\n",
            "Successfully imported model_backbone\n",
            "Successfully imported setup_dataholders\n"
          ]
        }
      ],
      "source": [
        "# Problems with importing files, so I had to manually add files to syspath\n",
        "import sys\n",
        "import os\n",
        "import importlib\n",
        "\n",
        "# Add the current working directory to sys.path\n",
        "sys.path.append(os.getcwd())\n",
        "\n",
        "# List of Python files you want to import\n",
        "modules = [\n",
        "    \"computer_vision_test_main\",\n",
        "    \"create_custom_dataset\",\n",
        "    \"firsttry_model\",\n",
        "    \"model_backbone\",\n",
        "    \"setup_dataholders\"\n",
        "]\n",
        "\n",
        "# Import each module and reload to avoid caching issues\n",
        "for module in modules:\n",
        "    try:\n",
        "        imported_module = __import__(module)\n",
        "        importlib.reload(imported_module)  # Reload in case it was modified\n",
        "        print(f\"Successfully imported {module}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error importing {module}: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6cF1NIRz3DI",
        "outputId": "5c6853dc-6efa-41a3-a50a-ac020c822cda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❌ Dataset folder is missing.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "dataset_path = \"data/fgvc-aircraft-2013b\"\n",
        "if os.path.exists(dataset_path):\n",
        "    print(\"✅ Dataset folder exists.\")\n",
        "    print(\"🗂 Contents:\", os.listdir(dataset_path))\n",
        "else:\n",
        "    print(\"❌ Dataset folder is missing.\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
