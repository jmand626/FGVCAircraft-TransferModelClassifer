{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This is the first cell, where image_path is defined\n",
        "from pathlib import Path\n",
        "\n",
        "# Define the path to the data folder\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"fgvc_aircraft\""
      ],
      "metadata": {
        "id": "9Sk080gYlXua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import zipfile\n",
        "import requests\n",
        "\n",
        "# 1️⃣ Mount Google Drive (if using for storage)\n",
        "use_gdrive = False  # Set to True if dataset is stored in Google Drive\n",
        "if use_gdrive:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "# 2️⃣ Clone your GitHub repo if it's not already present\n",
        "repo_url = \"https://github.com/jmand626/PyTorchMLEngine-Custom-Dataset-Project.git\"\n",
        "repo_name = \"PyTorchMLEngine-Custom-Dataset-Project\"\n",
        "\n",
        "if not os.path.exists(repo_name):\n",
        "    print(f\"Cloning {repo_url}...\")\n",
        "    !git clone {repo_url}\n",
        "else:\n",
        "    print(f\"Repository {repo_name} already exists.\")\n",
        "\n",
        "# 3️⃣ Change to repo directory ONLY ONCE\n",
        "os.chdir(repo_name) # This line sets the working directory\n",
        "\n",
        "# 4️⃣ Add project files to sys.path so imports work\n",
        "sys.path.append(os.getcwd())\n",
        "print(\"Project directory added to sys.path\")\n",
        "\n",
        "# 5️⃣ Ensure necessary dependencies are installed\n",
        "try:\n",
        "    import torchinfo\n",
        "except ImportError:\n",
        "    print(\"Installing torchinfo...\")\n",
        "    !pip install -q torchinfo\n",
        "\n",
        "# 6️⃣ Download FGVC Aircraft dataset if missing\n",
        "dataset_url = \"https://www.robots.ox.ac.uk/~vgg/data/fgvc-aircraft/archives/fgvc-aircraft-2013b.tar.gz\"\n",
        "dataset_tar = data_path / \"fgvc-aircraft-2013b.tar.gz\"\n",
        "dataset_folder = data_path / \"fgvc-aircraft-2013b\"\n",
        "\n",
        "if dataset_folder.exists():\n",
        "    print(\"Dataset already exists.\")\n",
        "else:\n",
        "    print(\"Downloading FGVC Aircraft dataset...\")\n",
        "    data_path.mkdir(parents=True, exist_ok=True)\n",
        "    response = requests.get(dataset_url, stream=True)\n",
        "    with open(dataset_tar, \"wb\") as f:\n",
        "        for chunk in response.iter_content(chunk_size=8192):\n",
        "            f.write(chunk)\n",
        "    print(\"Extracting dataset...\")\n",
        "    !tar -xzf {dataset_tar} -C {data_path}\n",
        "    os.remove(dataset_tar)\n",
        "    print(\"Dataset extraction complete.\")"
      ],
      "metadata": {
        "id": "GzSakdlhzbLN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "498133a5-6336-41a4-8b47-6f6b021aaf9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning https://github.com/jmand626/PyTorchMLEngine-Custom-Dataset-Project.git...\n",
            "Cloning into 'PyTorchMLEngine-Custom-Dataset-Project'...\n",
            "remote: Enumerating objects: 24, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 24 (delta 6), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (24/24), 21.93 KiB | 2.44 MiB/s, done.\n",
            "Resolving deltas: 100% (6/6), done.\n",
            "Project directory added to sys.path\n",
            "Installing torchinfo...\n",
            "Downloading FGVC Aircraft dataset...\n",
            "Extracting dataset...\n",
            "Dataset extraction complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPSxUj-_Teyf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85532681-7431-434b-92c7-bae62f0934b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] torch/torchvision versions not as required, installing nightly versions.\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m90.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "torch version: 2.6.0+cu124\n",
            "torchvision version: 0.21.0+cu124\n"
          ]
        }
      ],
      "source": [
        "# For this notebook to run with updated APIs, we need torch 1.12+ and torchvision 0.13+\n",
        "try:\n",
        "    import torch\n",
        "    import torchvision\n",
        "    assert int(torch.__version__.split(\".\")[1]) >= 12, \"torch version should be 1.12+\"\n",
        "    assert int(torchvision.__version__.split(\".\")[1]) >= 13, \"torchvision version should be 0.13+\"\n",
        "    print(f\"torch version: {torch.__version__}\")\n",
        "    print(f\"torchvision version: {torchvision.__version__}\")\n",
        "except:\n",
        "    print(f\"[INFO] torch/torchvision versions not as required, installing nightly versions.\")\n",
        "    !pip3 install -U torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "    import torch\n",
        "    import torchvision\n",
        "    print(f\"torch version: {torch.__version__}\")\n",
        "    print(f\"torchvision version: {torchvision.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpCWZh7Phbna",
        "outputId": "46960518-da6f-4440-eb92-6818e4140561"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "computer_vision_test_main.py  data\t\t model_backbone.py  setup_dataholders.py\n",
            "create_custom_dataset.py      firsttry_model.py  README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jt9KA4KSiTYJ",
        "outputId": "fe0a9d46-46dc-4bd8-bf7b-18548d307525"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now hopefully we can continously use the previous setup code whenever we want to use this dataset again."
      ],
      "metadata": {
        "id": "cMp0N0R2pW_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ipython-input-12-e84a44c78b2d\n",
        "# Assume the dataset is extracted to 'data/fgvc-aircraft-2013b'\n",
        "# and images are in 'data/fgvc-aircraft-2013b/data/images'\n",
        "from pathlib import Path # Make sure to import Path\n",
        "import os # Import os to get current working directory\n",
        "\n",
        "# Fix: Update paths to include the subfolder where the dataset was downloaded and extracted\n",
        "# Use os.path.join to create platform-independent paths\n",
        "# The issue was train_dir and test_dir were pointing to the wrong location.\n",
        "# They should point to the parent directory containing the class folders.\n",
        "train_dir = Path(os.path.join(os.getcwd(), \"data/fgvc-aircraft-2013b/data\")) # Corrected path\n",
        "test_dir = Path(os.path.join(os.getcwd(), \"data/fgvc-aircraft-2013b/data\"))  # Corrected path, assuming test images are in the same location\n",
        "\n",
        "\n",
        "# Print the resolved paths to verify they are correct\n",
        "print(\"Train directory:\", train_dir)\n",
        "print(\"Test directory:\", test_dir)"
      ],
      "metadata": {
        "id": "tKnebh8NpT7G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82bd2fce-9efc-498f-caf3-ab292d31b6cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train directory: /content/PyTorchMLEngine-Custom-Dataset-Project/data/fgvc-aircraft-2013b/data\n",
            "Test directory: /content/PyTorchMLEngine-Custom-Dataset-Project/data/fgvc-aircraft-2013b/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we continue on to creating our datasets and dataloaders. An important issue is that we have to ensure that the data that we feed into our pretrained model must be formatted in the same way as the data inputted when training the model (helps performance immeasurably). There is a certain way that all models from torchvision.models require, and we will do that.\n",
        "\n",
        "It is detailed in this page: https://docs.pytorch.org/vision/0.8/models.html"
      ],
      "metadata": {
        "id": "JWvJSUvVtJYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "import importlib\n",
        "import setup_dataholders\n",
        "importlib.reload(setup_dataholders)\n",
        "manual_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # 1. Reshape all images to 224x224 (though some models may require different sizes)\n",
        "    transforms.ToTensor(), # 2. Turn image values to between 0 & 1\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], # 3. A mean of [0.485, 0.456, 0.406] (across each colour channel)\n",
        "                         std=[0.229, 0.224, 0.225]) # 4. A standard deviation of [0.229, 0.224, 0.225] (across each colour channel),\n",
        "])"
      ],
      "metadata": {
        "id": "I2wsd6E2t64w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "# Define the path to the images directory\n",
        "images_dir = Path(\"data/fgvc-aircraft-2013b/data/images\")\n",
        "\n",
        "# Define the path to the labels file (variants.txt)\n",
        "labels_file = Path(\"data/fgvc-aircraft-2013b/data/variants.txt\")\n",
        "\n",
        "# Create a dictionary mapping image names to class labels\n",
        "image_to_class = {}\n",
        "with open(labels_file, \"r\") as f:\n",
        "    for line in f:\n",
        "        # Split the line using space as delimiter, but handle cases with missing values\n",
        "        parts = line.strip().split(\" \", 1)\n",
        "\n",
        "        # Check if the line has enough values to unpack\n",
        "        if len(parts) == 2:\n",
        "            image_name, class_label = parts\n",
        "            image_to_class[image_name + \".jpg\"] = class_label\n",
        "        else:\n",
        "            # Handle cases with missing values (e.g., print a warning or skip)\n",
        "            print(f\"Warning: Skipping line with missing data: {line.strip()}\")\n",
        "\n",
        "# Create class subfolders and move images\n",
        "for image_name, class_label in image_to_class.items():\n",
        "    image_path = images_dir / image_name\n",
        "    class_folder = images_dir / class_label\n",
        "    class_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Check if the file exists before attempting to move it\n",
        "    if image_path.exists():\n",
        "        shutil.move(str(image_path), str(class_folder))\n",
        "    else:\n",
        "        print(f\"Warning: File not found: {image_path}\")\n",
        "\n",
        "print(\"Dataset reorganized.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WjkCCglEFW_M",
        "outputId": "6f2e3727-300f-45c1-88f9-9a18b32e92d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Skipping line with missing data: 707-320\n",
            "Warning: Skipping line with missing data: 727-200\n",
            "Warning: Skipping line with missing data: 737-200\n",
            "Warning: Skipping line with missing data: 737-300\n",
            "Warning: Skipping line with missing data: 737-400\n",
            "Warning: Skipping line with missing data: 737-500\n",
            "Warning: Skipping line with missing data: 737-600\n",
            "Warning: Skipping line with missing data: 737-700\n",
            "Warning: Skipping line with missing data: 737-800\n",
            "Warning: Skipping line with missing data: 737-900\n",
            "Warning: Skipping line with missing data: 747-100\n",
            "Warning: Skipping line with missing data: 747-200\n",
            "Warning: Skipping line with missing data: 747-300\n",
            "Warning: Skipping line with missing data: 747-400\n",
            "Warning: Skipping line with missing data: 757-200\n",
            "Warning: Skipping line with missing data: 757-300\n",
            "Warning: Skipping line with missing data: 767-200\n",
            "Warning: Skipping line with missing data: 767-300\n",
            "Warning: Skipping line with missing data: 767-400\n",
            "Warning: Skipping line with missing data: 777-200\n",
            "Warning: Skipping line with missing data: 777-300\n",
            "Warning: Skipping line with missing data: A300B4\n",
            "Warning: Skipping line with missing data: A310\n",
            "Warning: Skipping line with missing data: A318\n",
            "Warning: Skipping line with missing data: A319\n",
            "Warning: Skipping line with missing data: A320\n",
            "Warning: Skipping line with missing data: A321\n",
            "Warning: Skipping line with missing data: A330-200\n",
            "Warning: Skipping line with missing data: A330-300\n",
            "Warning: Skipping line with missing data: A340-200\n",
            "Warning: Skipping line with missing data: A340-300\n",
            "Warning: Skipping line with missing data: A340-500\n",
            "Warning: Skipping line with missing data: A340-600\n",
            "Warning: Skipping line with missing data: A380\n",
            "Warning: Skipping line with missing data: ATR-42\n",
            "Warning: Skipping line with missing data: ATR-72\n",
            "Warning: Skipping line with missing data: An-12\n",
            "Warning: Skipping line with missing data: BAE-125\n",
            "Warning: Skipping line with missing data: C-130\n",
            "Warning: Skipping line with missing data: C-47\n",
            "Warning: Skipping line with missing data: CRJ-200\n",
            "Warning: Skipping line with missing data: CRJ-700\n",
            "Warning: Skipping line with missing data: CRJ-900\n",
            "Warning: Skipping line with missing data: DC-10\n",
            "Warning: Skipping line with missing data: DC-3\n",
            "Warning: Skipping line with missing data: DC-6\n",
            "Warning: Skipping line with missing data: DC-8\n",
            "Warning: Skipping line with missing data: DC-9-30\n",
            "Warning: Skipping line with missing data: DH-82\n",
            "Warning: Skipping line with missing data: DHC-1\n",
            "Warning: Skipping line with missing data: DHC-6\n",
            "Warning: Skipping line with missing data: DHC-8-100\n",
            "Warning: Skipping line with missing data: DHC-8-300\n",
            "Warning: Skipping line with missing data: DR-400\n",
            "Warning: Skipping line with missing data: E-170\n",
            "Warning: Skipping line with missing data: E-190\n",
            "Warning: Skipping line with missing data: E-195\n",
            "Warning: Skipping line with missing data: EMB-120\n",
            "Warning: Skipping line with missing data: F-16A/B\n",
            "Warning: Skipping line with missing data: F/A-18\n",
            "Warning: Skipping line with missing data: Il-76\n",
            "Warning: Skipping line with missing data: L-1011\n",
            "Warning: Skipping line with missing data: MD-11\n",
            "Warning: Skipping line with missing data: MD-80\n",
            "Warning: Skipping line with missing data: MD-87\n",
            "Warning: Skipping line with missing data: MD-90\n",
            "Warning: Skipping line with missing data: Metroliner\n",
            "Warning: Skipping line with missing data: PA-28\n",
            "Warning: Skipping line with missing data: SR-20\n",
            "Warning: Skipping line with missing data: Spitfire\n",
            "Warning: Skipping line with missing data: Tornado\n",
            "Warning: Skipping line with missing data: Tu-134\n",
            "Warning: Skipping line with missing data: Tu-154\n",
            "Warning: Skipping line with missing data: Yak-42\n",
            "Warning: File not found: data/fgvc-aircraft-2013b/data/images/BAE.jpg\n",
            "Warning: File not found: data/fgvc-aircraft-2013b/data/images/Beechcraft.jpg\n",
            "Warning: File not found: data/fgvc-aircraft-2013b/data/images/Boeing.jpg\n",
            "Warning: File not found: data/fgvc-aircraft-2013b/data/images/Cessna.jpg\n",
            "Warning: File not found: data/fgvc-aircraft-2013b/data/images/Challenger.jpg\n",
            "Warning: File not found: data/fgvc-aircraft-2013b/data/images/Dornier.jpg\n",
            "Warning: File not found: data/fgvc-aircraft-2013b/data/images/ERJ.jpg\n",
            "Warning: File not found: data/fgvc-aircraft-2013b/data/images/Embraer.jpg\n",
            "Warning: File not found: data/fgvc-aircraft-2013b/data/images/Eurofighter.jpg\n",
            "Warning: File not found: data/fgvc-aircraft-2013b/data/images/Falcon.jpg\n",
            "Warning: File not found: data/fgvc-aircraft-2013b/data/images/Fokker.jpg\n",
            "Warning: File not found: data/fgvc-aircraft-2013b/data/images/Global.jpg\n",
            "Warning: File not found: data/fgvc-aircraft-2013b/data/images/Gulfstream.jpg\n",
            "Warning: File not found: data/fgvc-aircraft-2013b/data/images/Hawk.jpg\n",
            "Warning: File not found: data/fgvc-aircraft-2013b/data/images/Model.jpg\n",
            "Warning: File not found: data/fgvc-aircraft-2013b/data/images/Saab.jpg\n",
            "Dataset reorganized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and testing DataLoaders as well as get a list of class names\n",
        "train_dataloader, test_dataloader, class_names = setup_dataholders.create_dataloaders(train_directory=train_dir,\n",
        "                                                                               test_directory=test_dir,\n",
        "                                                                               data_transforms=manual_transforms, # resize, convert images to between 0 & 1 and normalize them\n",
        "                                                                               batch_size=32, # set mini-batch size to 32\n",
        "                                                                               workers=4) # Fixed: removed type hint from the workers argument\n",
        "\n",
        "train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TC7PU_cxr7He",
        "outputId": "2bfa3990-0664-41a5-e7a9-d061cbb6a690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x791fdad65350>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x791fe3c45650>,\n",
              " ['images'])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next cells focus on the actual \"transfer\" part of taking a model from someplace else and using it for better performance. I could have done the transforms from the previous cells in a different way that is more automatic, but I wished to explore the more manual original way first."
      ],
      "metadata": {
        "id": "xG8FesLvNe3c"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IH_f5O39OjHE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}