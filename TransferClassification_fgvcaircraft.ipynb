{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jmand626/FGVCAircraft-TransferModelClassifer/blob/main/TransferClassification_fgvcaircraft.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiyyFonqfDOu",
        "outputId": "a613dbe1-693c-40cc-81cf-850e4357675e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nbstripout in /usr/local/lib/python3.12/dist-packages (0.8.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.12/dist-packages (from nbstripout) (5.10.4)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.12/dist-packages (from nbformat->nbstripout) (2.21.2)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.12/dist-packages (from nbformat->nbstripout) (4.25.1)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.12/dist-packages (from nbformat->nbstripout) (5.9.1)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.12/dist-packages (from nbformat->nbstripout) (5.7.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->nbstripout) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->nbstripout) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->nbstripout) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=2.6->nbformat->nbstripout) (0.28.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->nbstripout) (4.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from referencing>=0.28.4->jsonschema>=2.6->nbformat->nbstripout) (4.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install nbstripout\n",
        "!nbstripout \"/content/drive/MyDrive/Colab Notebooks/TransferClassification_fgvcaircraft.ipynb\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Sk080gYlXua"
      },
      "outputs": [],
      "source": [
        "# This is the first cell, where image_path is defined\n",
        "from pathlib import Path\n",
        "\n",
        "# Define the path to the data folder\n",
        "data_path = Path(\"/content/drive/MyDrive/data/\")\n",
        "image_path = data_path / \"fgvc_aircraft\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzSakdlhzbLN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import zipfile\n",
        "import requests\n",
        "\n",
        "# 1️ Mount Google Drive (if using for storage)\n",
        "use_gdrive = True  # Set to True if dataset is stored in Google Drive\n",
        "if use_gdrive:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "# 2️ Clone your GitHub repo if it's not already present\n",
        "repo_url = \"https://github.com/jmand626/PyTorchMLEngine-Custom-Dataset-Project.git\"\n",
        "repo_name = \"PyTorchMLEngine-Custom-Dataset-Project\"\n",
        "\n",
        "if not os.path.exists(repo_name):\n",
        "    print(f\"Cloning {repo_url}...\")\n",
        "    !git clone {repo_url}\n",
        "else:\n",
        "    print(f\"Repository {repo_name} already exists.\")\n",
        "\n",
        "# 3️ Change to repo directory ONLY ONCE\n",
        "os.chdir(repo_name) # This line sets the working directory\n",
        "\n",
        "# 4️ Add project files to sys.path so imports work\n",
        "sys.path.append(os.getcwd())\n",
        "print(\"Project directory added to sys.path\")\n",
        "\n",
        "# 5️ Ensure necessary dependencies are installed\n",
        "try:\n",
        "    import torchinfo\n",
        "except ImportError:\n",
        "    print(\"Installing torchinfo...\")\n",
        "    !pip install -q torchinfo\n",
        "\n",
        "# 6️ Download FGVC Aircraft dataset if missing\n",
        "dataset_url = \"https://www.robots.ox.ac.uk/~vgg/data/fgvc-aircraft/archives/fgvc-aircraft-2013b.tar.gz\"\n",
        "dataset_tar = data_path / \"fgvc-aircraft-2013b.tar.gz\"\n",
        "dataset_folder = data_path / \"fgvc-aircraft-2013b\"\n",
        "# Define a file within the extracted dataset to check for existence\n",
        "check_file = dataset_folder / \"data/images/0034309.jpg\"\n",
        "\n",
        "if check_file.exists():\n",
        "    print(\"Dataset already exists.\")\n",
        "else:\n",
        "    print(\"Downloading FGVC Aircraft dataset...\")\n",
        "    data_path.mkdir(parents=True, exist_ok=True)\n",
        "    response = requests.get(dataset_url, stream=True)\n",
        "    with open(dataset_tar, \"wb\") as f:\n",
        "        for chunk in response.iter_content(chunk_size=8192):\n",
        "            f.write(chunk)\n",
        "    print(\"Extracting dataset...\")\n",
        "    !tar -xzf {dataset_tar} -C {data_path}\n",
        "    os.remove(dataset_tar)\n",
        "    print(\"Dataset extraction complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPSxUj-_Teyf"
      },
      "outputs": [],
      "source": [
        "# For this notebook to run with updated APIs, we need torch 1.12+ and torchvision 0.13+\n",
        "try:\n",
        "    import torch\n",
        "    import torchvision\n",
        "    assert int(torch.__version__.split(\".\")[1]) >= 12, \"torch version should be 1.12+\"\n",
        "    assert int(torchvision.__version__.split(\".\")[1]) >= 13, \"torchvision version should be 0.13+\"\n",
        "    print(f\"torch version: {torch.__version__}\")\n",
        "    print(f\"torchvision version: {torchvision.__version__}\")\n",
        "except:\n",
        "    print(f\"[INFO] torch/torchvision versions not as required, installing nightly versions.\")\n",
        "    !pip3 install -U torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "    import torch\n",
        "    import torchvision\n",
        "    print(f\"torch version: {torch.__version__}\")\n",
        "    print(f\"torchvision version: {torchvision.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpCWZh7Phbna"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igLk5J4rC7EI"
      },
      "outputs": [],
      "source": [
        "import model_backbone\n",
        "import setup_dataholders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jt9KA4KSiTYJ"
      },
      "outputs": [],
      "source": [
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMp0N0R2pW_g"
      },
      "source": [
        "Now hopefully we can continously use the previous setup code whenever we want to use this dataset again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSEoF7y_p6ig"
      },
      "outputs": [],
      "source": [
        "!ls /content/drive/MyDrive/data/fgvc-aircraft-2013b/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Id2xd_0eSLQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "# Define the path to the data folder on Google Drive\n",
        "data_path = Path(\"/content/drive/MyDrive/data/\")\n",
        "dataset_folder = data_path / \"fgvc-aircraft-2013b\"\n",
        "images_base_dir = dataset_folder / \"data\" / \"images\" # Base directory where images are now in class subfolders\n",
        "\n",
        "# Define paths to the train and test mapping files\n",
        "train_mapping_file = dataset_folder / \"data\" / \"images_variant_train.txt\"\n",
        "test_mapping_file = dataset_folder / \"data\" / \"images_variant_test.txt\"\n",
        "variants_file = dataset_folder / \"data\" / \"variants.txt\" # File containing all class names\n",
        "\n",
        "# Define the target root directories for the train and test splits\n",
        "train_root_dir = dataset_folder / \"train\"\n",
        "test_root_dir = dataset_folder / \"test\"\n",
        "\n",
        "# Function to check if the directories are populated\n",
        "def is_populated(directory):\n",
        "    if not directory.exists():\n",
        "        return False\n",
        "    # Check if there are any subdirectories (which represent classes)\n",
        "    if not any(directory.iterdir()):\n",
        "        return False\n",
        "    # You could add a more robust check here, like checking if a certain number of\n",
        "    # class directories exist or if a specific file exists in a class directory.\n",
        "    return True\n",
        "\n",
        "# Check if directories are already populated\n",
        "if is_populated(train_root_dir) and is_populated(test_root_dir):\n",
        "    print(\"Train and test directories are already populated. Skipping population.\")\n",
        "else:\n",
        "    print(\"Train and test directories are not populated or incomplete. Populating now...\")\n",
        "\n",
        "    # Ensure the target root directories exist and are empty or can be overwritten if not populated\n",
        "    for dir_path in [train_root_dir, test_root_dir]:\n",
        "        if dir_path.exists() and not is_populated(dir_path):\n",
        "            print(f\"Removing incomplete existing directory: {dir_path}\")\n",
        "            shutil.rmtree(dir_path)\n",
        "        dir_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Get the full list of class names from variants.txt\n",
        "    all_class_names = []\n",
        "    with open(variants_file, \"r\") as f:\n",
        "        for line in f:\n",
        "            all_class_names.append(line.strip())\n",
        "    all_class_names = sorted(list(set(all_class_names))) # Remove duplicates and sort\n",
        "\n",
        "    print(f\"Found {len(all_class_names)} unique class names from variants.txt.\")\n",
        "\n",
        "    # Create all class subdirectories within the train and test root directories\n",
        "    print(\"Creating all class subdirectories in train and test folders...\")\n",
        "    for class_name in all_class_names:\n",
        "        sanitized_class_folder_name = class_name.replace(\" \", \"_\").replace(\"/\", \"_\").replace(\"-\", \"_\")\n",
        "        (train_root_dir / sanitized_class_folder_name).mkdir(parents=True, exist_ok=True)\n",
        "        (test_root_dir / sanitized_class_folder_name).mkdir(parents=True, exist_ok=True)\n",
        "    print(\"Class subdirectories created.\")\n",
        "\n",
        "\n",
        "    # Function to read mapping files and get image ID to label mapping\n",
        "    def read_mapping_file(filepath):\n",
        "        image_id_to_class = {}\n",
        "        with open(filepath, \"r\") as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split(\" \", 1)\n",
        "                if len(parts) == 2:\n",
        "                    image_id, label = parts\n",
        "                    image_id_to_class[image_id] = label\n",
        "                else:\n",
        "                     print(f\"Warning: Skipping line in {filepath.name} with unexpected format: {line.strip()}\")\n",
        "        return image_id_to_class\n",
        "\n",
        "    # Read mappings for train and test sets\n",
        "    train_image_id_to_class = read_mapping_file(train_mapping_file)\n",
        "    test_image_id_to_class = read_mapping_file(test_mapping_file)\n",
        "\n",
        "    print(f\"Found mappings for {len(train_image_id_to_class)} training images.\")\n",
        "    print(f\"Found mappings for {len(test_image_id_to_class)} testing images.\")\n",
        "\n",
        "    # Function to copy images for a given split based on mappings\n",
        "    def populate_split_directories(image_id_to_class_mapping, target_root_dir, images_base_dir):\n",
        "        copied_count = 0\n",
        "        source_not_found_count = 0\n",
        "        target_folder_not_found_count = 0\n",
        "\n",
        "        print(f\"Populating {target_root_dir} with images...\")\n",
        "\n",
        "        for image_id, class_label in image_id_to_class_mapping.items():\n",
        "            image_name = f\"{image_id}.jpg\"\n",
        "            sanitized_class_folder_name = class_label.replace(\" \", \"_\").replace(\"/\", \"_\").replace(\"-\", \"_\")\n",
        "\n",
        "            # Source path: Look for the image within the existing class subfolders in images_base_dir\n",
        "            source_image_path = images_base_dir / sanitized_class_folder_name / image_name\n",
        "\n",
        "            # Target path: The location in the new train/test class folder (already created)\n",
        "            target_class_folder = target_root_dir / sanitized_class_folder_name\n",
        "            target_image_path = target_class_folder / image_name\n",
        "\n",
        "            if source_image_path.exists():\n",
        "                if target_class_folder.exists(): # Ensure target class folder was created\n",
        "                    if not target_image_path.exists():\n",
        "                        try:\n",
        "                            shutil.copy(str(source_image_path), str(target_image_path))\n",
        "                            copied_count += 1\n",
        "                        except Exception as e:\n",
        "                            print(f\"Error copying file {source_image_path} to {target_class_folder}: {e}\")\n",
        "                else:\n",
        "                    print(f\"Error: Target class folder not found for {class_label}: {target_class_folder}\")\n",
        "                    target_folder_not_found_count += 1\n",
        "            else:\n",
        "                print(f\"Warning: Source image file not found: {source_image_path}\")\n",
        "                source_not_found_count += 1\n",
        "\n",
        "        print(f\"Finished populating {target_root_dir}. Copied {copied_count} images. {source_not_found_count} source images not found. {target_folder_not_found_count} target class folders not found.\")\n",
        "\n",
        "\n",
        "    # Populate train and test directories\n",
        "    populate_split_directories(train_image_id_to_class, train_root_dir, images_base_dir)\n",
        "    populate_split_directories(test_image_id_to_class, test_root_dir, images_base_dir)\n",
        "\n",
        "\n",
        "    print(\"Dataset reorganization and population complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlxMipUrZqx5"
      },
      "source": [
        "Will have to put new cell here and make some edits to change how the data is loaded. Currently, I have the dataset downloaded to my drive and the dataloaders have to take all of the data from their piece by piece, but it should be much faster to instead upon each section, copy all data from drive to the local colab vm and then continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8mog7TYbKG2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "print(\"Copying dataset from Google Drive to local VM...\")\n",
        "print(\"This may take a few minutes, but it's a one-time operation.\")\n",
        "\n",
        "# Define local paths\n",
        "local_train_dir = \"/content/train\"\n",
        "local_test_dir = \"/content/test\"\n",
        "\n",
        "# Define GDrive paths\n",
        "gdrive_train_dir = \"/content/drive/MyDrive/data/fgvc-aircraft-2013b/train\"\n",
        "gdrive_test_dir = \"/content/drive/MyDrive/data/fgvc-aircraft-2013b/test\"\n",
        "\n",
        "# Run the copy commands (only if not already copied)\n",
        "if not os.path.exists(local_train_dir):\n",
        "    print(\"Copying train set...\")\n",
        "    !cp -r {gdrive_train_dir} {local_train_dir}\n",
        "    print(\"Train set copied.\")\n",
        "else:\n",
        "    print(\"Train set already on local VM.\")\n",
        "\n",
        "if not os.path.exists(local_test_dir):\n",
        "    print(\"Copying test set...\")\n",
        "    !cp -r {gdrive_test_dir} {local_test_dir}\n",
        "    print(\"Test set copied.\")\n",
        "else:\n",
        "    print(\"Test set already on local VM.\")\n",
        "\n",
        "print(\"Copying complete. You can now proceed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKnebh8NpT7G"
      },
      "outputs": [],
      "source": [
        "# ipython-input-12-e84a44c78b2d\n",
        "# Assume the dataset is extracted to 'data/fgvc-aircraft-2013b'\n",
        "# and images are in 'data/fgvc-aircraft-2013b/data/images'\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "#data_path = Path(\"/content/drive/MyDrive/data/\") # This variable is defined in the first cell\n",
        "#dataset_folder = data_path / \"fgvc-aircraft-2013b\"\n",
        "\n",
        "#train_dir = dataset_folder / \"data\" / \"images\"\n",
        "#test_dir = dataset_folder / \"data\" / \"images\"\n",
        "\n",
        "train_dir = \"/content/train\"\n",
        "test_dir = \"/content/test\"\n",
        "\n",
        "\n",
        "# Print the resolved paths to verify they are correct\n",
        "print(\"Train directory:\", train_dir)\n",
        "print(\"Test directory:\", test_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWvJSUvVtJYy"
      },
      "source": [
        "Now we continue on to creating our datasets and dataloaders. An important issue is that we have to ensure that the data that we feed into our pretrained model must be formatted in the same way as the data inputted when training the model (as that helps performance immeasurably). There is a certain way that all models from torchvision.models require, and we will do that.\n",
        "\n",
        "It is detailed in this page: https://docs.pytorch.org/vision/0.8/models.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2wsd6E2t64w"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "import importlib\n",
        "import setup_dataholders\n",
        "importlib.reload(setup_dataholders)\n",
        "manual_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)), # 1. Reshape all images to 224x224 (though some models may require different sizes)\n",
        "    transforms.ToTensor(), # 2. Turn image values to between 0 & 1\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], # 3. A mean of [0.485, 0.456, 0.406] (across each color channel)\n",
        "                         std=[0.229, 0.224, 0.225]) # 4. A standard deviation of [0.229, 0.224, 0.225] (across each color channel),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TC7PU_cxr7He"
      },
      "outputs": [],
      "source": [
        "# Create training and testing DataLoaders as well as get a list of class names\n",
        "train_dataloader, test_dataloader, class_names = setup_dataholders.create_dataloaders(train_directory=train_dir,\n",
        "                                                                               test_directory=test_dir,\n",
        "                                                                               data_transforms=manual_transforms, # resize, convert images to between 0 & 1 and normalize them\n",
        "                                                                               batch_size=32, # set mini-batch size to 32\n",
        "                                                                               workers=0)\n",
        "\n",
        "train_dataloader, test_dataloader, class_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xG8FesLvNe3c"
      },
      "source": [
        "The next cells focus on the actual \"transfer\" part of taking a model from someplace else and using it for better performance. I could have done the transforms from the previous cells in a different way that is more automatic, but I wished to explore the more manual original way first."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FS12EZlOmSSx"
      },
      "source": [
        "Now onto taking a different model and applying it here! We will use the [EfficentNet_v2_m](https://docs.pytorch.org/vision/stable/models/generated/torchvision.models.efficientnet_v2_m.html#torchvision.models.efficientnet_v2_m) model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lju21leDmfw7"
      },
      "outputs": [],
      "source": [
        "weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n",
        "model = torchvision.models.efficientnet_b0(weights=weights).to(device)\n",
        "\n",
        "# Take the precalculated features, avgpool calculation, and the classifier from the transfered model and apply it to our problem!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEiusxPMpMBe"
      },
      "outputs": [],
      "source": [
        "# Print a summary using torchinfo\n",
        "from torchinfo import summary\n",
        "\n",
        "summary(model=model,\n",
        "        input_size=(32, 3, 480, 480), # make sure this is \"input_size\", not \"input_shape\"\n",
        "        # col_names=[\"input_size\"], # uncomment for smaller output\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugnPgmwo-eNh"
      },
      "source": [
        "Now we want to freeze some layers of this model because that means we do not have to train them again!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Myay1QAK-oE8"
      },
      "outputs": [],
      "source": [
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnfKhpDK-9zy"
      },
      "source": [
        "Update our model to now use 102 classes instead, since our dataset only had 102 variants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FG0xSRho-ypn"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# From before\n",
        "output_shape = len(class_names)\n",
        "# Recreate the classifier layer and seed it to the target device\n",
        "model.classifier = torch.nn.Sequential(\n",
        "    torch.nn.Dropout(p=0.2, inplace=True),\n",
        "    torch.nn.Linear(in_features=1280,\n",
        "                    out_features=output_shape, # same number of output units as our number of classes\n",
        "                    bias=True)).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBX2l29iFx16"
      },
      "outputs": [],
      "source": [
        "model = model.to(device)\n",
        "print(f\"Model device: {next(model.parameters()).device}\")\n",
        "print(f\"Classifier device: {model.classifier[1].weight.device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaL5GEqDA_FH"
      },
      "outputs": [],
      "source": [
        "summary(model,\n",
        "        input_size=(32, 3, 224, 224), # make sure this is \"input_size\", not \"input_shape\" (batch_size, color_channels, height, width)\n",
        "        verbose=0,\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVLqWLGTBsDp"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kxv-ruwaBz1C"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Check setup first\n",
        "print(\"=\" * 60)\n",
        "print(\"TRAINING SETUP CHECK\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Device: {device}\")\n",
        "print(f\"Model device: {next(model.parameters()).device}\")\n",
        "print(f\"Training samples: {len(train_dataloader.dataset)}\")\n",
        "print(f\"Training batches: {len(train_dataloader)}\")\n",
        "print(f\"Testing samples: {len(test_dataloader.dataset)}\")\n",
        "print(f\"Testing batches: {len(test_dataloader)}\")\n",
        "print(f\"Batch size: {train_dataloader.batch_size}\")\n",
        "print(f\"Workers: {train_dataloader.num_workers}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Test one batch first\n",
        "print(\"\\nTesting forward pass with one batch...\")\n",
        "images, labels = next(iter(train_dataloader))\n",
        "images, labels = images.to(device), labels.to(device)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    output = model(images)\n",
        "    print(f\"✓ Forward pass successful! Output shape: {output.shape}\")\n",
        "model.train()\n",
        "\n",
        "# Now train\n",
        "print(\"\\nStarting training... (this may take 5-10 minutes per epoch)\")\n",
        "from timeit import default_timer as timer\n",
        "start_time = timer()\n",
        "\n",
        "results = model_backbone.train(\n",
        "    model=model,\n",
        "    train_dataloader=train_dataloader,\n",
        "    test_dataloader=test_dataloader,\n",
        "    optimizer=optimizer,\n",
        "    loss_fn=loss_fn,\n",
        "    epochs=5,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "end_time = timer()\n",
        "print(f\"[INFO] Total training time: {end_time-start_time:.3f} seconds\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHSTwf4nC_CY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}